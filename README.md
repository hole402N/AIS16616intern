# AIS16616intern
# Day 1-

i) First thing we learned, how to download Anaconda software. We download software from anaconda.org and complete rest of process to run software.
ii) We explore Anaconda software and learned new softwares from it, like R software, Jupiter Notebook, Jupiter Lab, etc. 
iii) In Jupiter notebook we learned how to create jupiter notebook and how to run it.
     By the end of the day we learned a lot of things that will benefit us a lot for this internship and we learned how to do coding in Jupiter notebook.

# Task 1-

 i) We learned  Operators. Operators we have Arithmetic, Assignment, Comparison, Logical, Identity, Membership and etc.Looked at some of these types and learned how to use         them.
 ii) After this we learned what is variable selection in python. We saw the different rules of how to create variables, how to write variable names.And also saw examples            of variable selection.
 iii) Then we learned what Data Types are. There are two types of data types, Mutable Data Types and Immutable Data Types. 1) Mutable Data Types include List, Set, 
      Dictionary Data Types. And saw examples of each. 2) Immutable Data Types include Numerical, String and Tuple Data Types and saw some examples.

# Task 2-

i) In Task 2 we saw some different conditions like if, if else, if elif, etc. In these conditions we have seen how their syntax works. And learned when and why to use these condition.
 ii)Learned what Loops are. And saw 2 types of loops, for loop and while loop. We understand when to use for loop and while loop, and how to use it.

# Task 3-

i) It was statement regarding. In it we learned what Break, Pass and Continue statement are and how they are used in for loop and while loop. And from the name we can understand that what will be their work. Break is used to break a loop, etc
 ii) After this we learned what statistical user defined function is. A function was created using statistical concept in it. Just created a function using its formula to find the mean.
 iii) Later learned what Logical user defined function is. Using this concept, a function was created after understanding the logic behind any concept or any formula.

# Task 4-

1. Numpy library: basic,random(distribution and visualization),universalfunstion.

# Task 5-

1. Pandas series creation and operation.
2. Dataframe creation using matrix,dictionary and xlsx file.
3. Dataframe operation or dataframe method in pandas.
4. selection in dataframes:row or column selection,delete,update,index,remove index etc.operation between two rows or columns in dataframe.
5. Missing Values:checking for missing values,dropping missing values,fill missing value.

# Task 6-

1. Matplot library for visualisation : scatter plot ,line plot,histohram,pie chart,etc.customization in this plot like colour,legend,size ,etc.
2. seaborn library : seaborn is a library that uses Matplotlib underneath to plot graphs.

# Task 7-

 In task 7 we solve some exercise like Ecommerce purcheses exercise,Numpy exercise and SF Salaries Exercise.

 # Case Study-

 conducted case study on data set of titanic which is available on kaggle.
Case study:

* Download titanic data
1. read data and import necessary libraries 
 data preprocessing : 
2. find missing value ,fill or drop
3. if need drop variable 
4. label encoding for categorical variable 

* Visualisation:
 EDA: bar plot , scatter plot ,joint bar plot,Pai chart, etc

* Model building:
5.choose dependent and independent variables
6.split data into train test ,80:20
7.import naive bayâ€™s algorithms 
8.fit naive bays model on train data
9.predict text data using fitted model

* Model evaluation: 
10.find accuracy 
11.find classification report 
12.find confusion matrics 

* Same process for :
8.knn algorithm 
9.decision tree

* Comparison:
Naive bays , knn,decision tree compair 
Accuracy,recall, precision

 # Final Project
  We done our project on the data set of "Customer Churn Analysis".
   Then we done a Data Preprocessing,Visualisation,Model Building,Model Evaluation by using the different types of algorithms.Then we plot a comparision graphs on base algorithms Accuracy vs gridsearchcv's algorithm Accuracy and done these same process for precision.Then we create a another file for feature importance here we done same procedure Data Preprocessing,Model Building,Model Evaluation by using the different types of algorithms.Then we plot a comparision graphs on base algorithms Accuracy vs gridsearchcv's algorithm Accuracy and done these same process for precision.

* Here we create visualisation on Dashboard using Power-bi.

    
  
